 ELT Pipeline with dbt & Snowflake
This project is a guided code-along for building a complete ELT (Extract, Load, Transform) pipeline using dbt and Snowflake, based on the "Code Along - Build an ELT Pipeline in 1 Hour" tutorial. Airflow integration is not included in this version.

ğŸ§± Tech Stack
dbt (data build tool) â€“ for data transformations

Snowflake â€“ for data warehouse and storage

SQL â€“ for all data modeling and transformation logic

ğŸ“¦ Project Structure
bash
Copy
Edit
â”œâ”€â”€ macros/                 # Custom reusable macros
â”‚   â””â”€â”€ pricing.sql         # Macro to calculate discounted amount
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/            # Staging layer
â”‚   â”‚   â”œâ”€â”€ tpch_sources.yml
â”‚   â”‚   â”œâ”€â”€ stg_tpch_orders.sql
â”‚   â”‚   â””â”€â”€ tpch/stg_tpch_line_items.sql
â”‚   â””â”€â”€ marts/              # Data marts and fact tables
â”‚       â”œâ”€â”€ int_order_items.sql
â”‚       â”œâ”€â”€ int_order_items_summary.sql
â”‚       â”œâ”€â”€ fct_orders.sql
â”‚       â””â”€â”€ generic_tests.yml
â”œâ”€â”€ tests/                  # Singular test cases
â”‚   â”œâ”€â”€ fct_orders_discount.sql
â”‚   â””â”€â”€ fct_orders_date_valid.sql
â””â”€â”€ dbt_project.yml         # dbt project configuration
ğŸ› ï¸ Setup Instructions
1. Snowflake Environment Setup
Use the following SQL commands in Snowflake to set up the environment:

sql
Copy
Edit
use role accountadmin;

create warehouse dbt_wh with warehouse_size='x-small';
create database if not exists dbt_db;
create role if not exists dbt_role;

grant role dbt_role to user <your_user>;
grant usage on warehouse dbt_wh to role dbt_role;
grant all on database dbt_db to role dbt_role;

use role dbt_role;
create schema if not exists dbt_db.dbt_schema;
2. Configure profiles.yml
Example profiles.yml:

yaml
Copy
Edit
snowflake_workshop:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: <account_name>
      user: <your_username>
      password: <your_password>
      role: dbt_role
      database: dbt_db
      warehouse: dbt_wh
      schema: dbt_schema
      threads: 1
3. Add Models
Sources & Staging: Define orders and lineitem from Snowflake sample data

Macros: Create a utility function to calculate discounts

Transformations: Generate intermediate and fact tables

Tests: Add generic and custom tests to validate data quality

âœ… dbt Workflow
To run your transformations and tests:

bash
Copy
Edit
dbt debug               # Validate configuration
dbt deps                # Install dependencies
dbt run                 # Execute models
dbt test                # Run data quality tests
dbt docs generate       # Generate documentation
dbt docs serve          # View docs in browser
ğŸ§ª Tests Included
Generic Tests: Uniqueness, not null, relationships, accepted values

Singular Tests: Business logic validations for discounts and valid order dates
